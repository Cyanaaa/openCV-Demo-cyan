# Human Pose Classification with MediaPipe and OpenCV

This project demonstrates how to classify human poses (Standing, Sitting, Lying) using **MediaPipe Pose** and **scikit-learn**, with real-time inference via **OpenCV** and **a webcam or video input**.


## ğŸ“Œ Features

- âœ… Extract skeleton keypoints using MediaPipe Pose
- âœ… Calculate body joint angles (hip-based)
- âœ… Train a classifier (Random Forest) to distinguish 3 poses:
  - `Stand`
  - `Sit`
  - `Lie`
- âœ… Real-time webcam detection
- âœ… Full visualization of the skeleton and predictions
- âœ… Support for automated frame extraction from labeled videos

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ videos/                    # Raw MP4 videos, one action per file (e.g. sit_1.mp4)
â”œâ”€â”€ dataset_clean/            # Extracted and filtered frames
â”œâ”€â”€ pose_classifier.pkl       # Trained model
â”œâ”€â”€ step1_extract_and_filter.py   # Extract frames + filter invalid skeletons
â”œâ”€â”€ step2_train_model.py          # Train classifier
â”œâ”€â”€ step3_classify_camera.py      # Realtime webcam classification (with skeleton)
```

---

## âš™ï¸ Setup

1. Create virtual environment:
   ```bash
   conda create -n opencv_pose python=3.10
   conda activate opencv_pose
   ```

2. Install dependencies:
   ```bash
   pip install mediapipe opencv-python scikit-learn tqdm joblib
   ```

---

## ğŸƒ Usage

### 1. Extract Labeled Frames from Videos

Put your labeled videos into the `videos/` folder. Each filename should include the class: `stand`, `sit`, or `lie`.

```bash
python step1_extract_and_filter.py
```

This will:
- Read each video
- Extract frames every N frames
- Discard frames where no full skeleton is detected
- Save cleaned frames to `dataset_clean/`

---

### 2. Train the Pose Classifier

```bash
python step2_train_model.py
```

- Calculates angles (shoulder-hip-knee) for each image
- Trains a RandomForest classifier
- Saves model as `pose_classifier.pkl`

---

### 3. Run Real-Time Webcam Inference

```bash
python step3_classify_camera.py
```

This will:
- Start your webcam
- Run real-time pose detection
- Display skeleton and predicted label (`Stand`, `Sit`, `Lie`)

---

## ğŸ“ Educational Goals

This tutorial is designed for students to:
- Understand human pose estimation using skeleton keypoints
- Learn how to extract features (joint angles) for classification
- Build interpretable models for real-world applications (elderly care, fall detection)
- Practice working with OpenCV and MediaPipe in Python

---

## ğŸ“· Example Videos

> You may record 3 short videos demonstrating standing, sitting, and lying to use as training input.

---

## ğŸ”’ License

MIT License

---

## ğŸ™‹â€â™‚ï¸ Author

Developed for teaching purposes by [Your Name], 2025  
Feel free to fork, modify, and use in your own projects!
